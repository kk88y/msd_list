--- a/mac80211.c
+++ b/mac80211.c
@@ -921,8 +921,7 @@
 {
 	struct ieee80211_sta *sta;
 	struct ieee80211_hw *hw;
-	struct sk_buff *skb, *tmp;
-	LIST_HEAD(list);
+	struct sk_buff *skb;
 
 	spin_lock(&dev->rx_lock);
 	while ((skb = __skb_dequeue(frames)) != NULL) {
@@ -1011,7 +1010,7 @@
 
 		skb_shinfo(skb)->frag_list = NULL;
 		mt76_rx_convert(dev, skb, &hw, &sta);
-		ieee80211_rx_list(hw, sta, skb, &list);
+		ieee80211_rx_napi(hw, sta, skb, napi);
 
 		/* subsequent amsdu frames */
 		while (nskb) {
@@ -1020,20 +1019,10 @@
 			skb->next = NULL;
 
 			mt76_rx_convert(dev, skb, &hw, &sta);
-			ieee80211_rx_list(hw, sta, skb, &list);
+			ieee80211_rx_napi(hw, sta, skb, napi);
 		}
 	}
 	spin_unlock(&dev->rx_lock);
-
-	if (!napi) {
-		netif_receive_skb_list(&list);
-		return;
-	}
-
-	list_for_each_entry_safe(skb, tmp, &list, list) {
-		skb_list_del_init(skb);
-		napi_gro_receive(napi, skb);
-	}
 }
 
 void mt76_rx_poll_complete(struct mt76_dev *dev, enum mt76_rxq_id q,
--- a/mt76.h
+++ b/mt76.h
@@ -1056,13 +1056,7 @@
 				       struct sk_buff_head *list);
 void mt76_tx_status_skb_done(struct mt76_dev *dev, struct sk_buff *skb,
 			     struct sk_buff_head *list);
-void __mt76_tx_complete_skb(struct mt76_dev *dev, u16 wcid, struct sk_buff *skb,
-			    struct list_head *free_list);
-static inline void
-mt76_tx_complete_skb(struct mt76_dev *dev, u16 wcid, struct sk_buff *skb)
-{
-    __mt76_tx_complete_skb(dev, wcid, skb, NULL);
-}
+void mt76_tx_complete_skb(struct mt76_dev *dev, u16 wcid, struct sk_buff *skb);
 
 void mt76_tx_status_check(struct mt76_dev *dev, struct mt76_wcid *wcid,
 			  bool flush);
--- a/tx.c
+++ b/tx.c
@@ -54,23 +54,11 @@
 
 	spin_unlock_bh(&dev->status_list.lock);
 
-	rcu_read_lock();
 	while ((skb = __skb_dequeue(list)) != NULL) {
-		struct ieee80211_tx_status status = {
-			.skb = skb,
-			.info = IEEE80211_SKB_CB(skb),
-		};
-		struct mt76_tx_cb *cb = mt76_tx_skb_cb(skb);
-		struct mt76_wcid *wcid;
-
-		wcid = rcu_dereference(dev->wcid[cb->wcid]);
-		if (wcid)
-			status.sta = wcid_to_sta(wcid);
-
 		hw = mt76_tx_status_get_hw(dev, skb);
-		ieee80211_tx_status_ext(hw, &status);
+		ieee80211_tx_status(hw, skb);
 	}
-	rcu_read_unlock();
+
 }
 EXPORT_SYMBOL_GPL(mt76_tx_status_unlock);
 
@@ -92,7 +80,7 @@
 
 	/* Tx status can be unreliable. if it fails, mark the frame as ACKed */
 	if (flags & MT_TX_CB_TXS_FAILED) {
-		info->status.rates[0].count = 0;
+		ieee80211_tx_info_clear_status(info);
 		info->status.rates[0].idx = -1;
 		info->flags |= IEEE80211_TX_STAT_ACK;
 	}
@@ -185,37 +173,36 @@
 EXPORT_SYMBOL_GPL(mt76_tx_status_check);
 
 static void
-mt76_tx_check_non_aql(struct mt76_dev *dev, struct mt76_wcid *wcid,
-		      struct sk_buff *skb)
+mt76_tx_check_non_aql(struct mt76_dev *dev, u16 wcid_idx, struct sk_buff *skb)
 {
 	struct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);
+	struct mt76_wcid *wcid;
 	int pending;
 
-	if (!wcid || info->tx_time_est)
+	if (info->tx_time_est)
 		return;
 
-	pending = atomic_dec_return(&wcid->non_aql_packets);
-	if (pending < 0)
-		atomic_cmpxchg(&wcid->non_aql_packets, pending, 0);
+	if (wcid_idx >= ARRAY_SIZE(dev->wcid))
+		return;
+
+	rcu_read_lock();
+
+	wcid = rcu_dereference(dev->wcid[wcid_idx]);
+	if (wcid) {
+		pending = atomic_dec_return(&wcid->non_aql_packets);
+		if (pending < 0)
+			atomic_cmpxchg(&wcid->non_aql_packets, pending, 0);
+	}
+
+	rcu_read_unlock();
 }
 
-void __mt76_tx_complete_skb(struct mt76_dev *dev, u16 wcid_idx, struct sk_buff *skb,
-			    struct list_head *free_list)
-{
-	struct ieee80211_tx_status status = {
-		.skb = skb,
-		.free_list = free_list,
-	};
-	struct mt76_wcid *wcid = NULL;
+void mt76_tx_complete_skb(struct mt76_dev *dev, u16 wcid_idx, struct sk_buff *skb)
+{
 	struct ieee80211_hw *hw;
 	struct sk_buff_head list;
 
-	rcu_read_lock();
-
-	if (wcid_idx < ARRAY_SIZE(dev->wcid))
-		wcid = rcu_dereference(dev->wcid[wcid_idx]);
-
-	mt76_tx_check_non_aql(dev, wcid, skb);
+	mt76_tx_check_non_aql(dev, wcid_idx, skb);
 
 #ifdef CONFIG_NL80211_TESTMODE
 	if (mt76_is_testmode_skb(dev, skb, &hw)) {
@@ -227,25 +214,21 @@
 			wake_up(&dev->tx_wait);
 
 		dev_kfree_skb_any(skb);
-		goto out;
+		return;
 	}
 #endif
 
 	if (!skb->prev) {
 		hw = mt76_tx_status_get_hw(dev, skb);
-		status.sta = wcid_to_sta(wcid);
-		ieee80211_tx_status_ext(hw, &status);
-		goto out;
+		ieee80211_free_txskb(hw, skb);
+		return;
 	}
 
 	mt76_tx_status_lock(dev, &list);
 	__mt76_tx_status_skb_done(dev, skb, MT_TX_CB_DMA_DONE, &list);
 	mt76_tx_status_unlock(dev, &list);
-
-out:
-	rcu_read_unlock();
 }
-EXPORT_SYMBOL_GPL(__mt76_tx_complete_skb);
+EXPORT_SYMBOL_GPL(mt76_tx_complete_skb);
 
 static int
 __mt76_tx_queue_skb(struct mt76_phy *phy, int qid, struct sk_buff *skb,
